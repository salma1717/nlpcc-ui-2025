{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk2v98JCQF7rXMRnTay9F+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salma1717/nlpcc-ui-2025/blob/main/Class_5%266_Assignment_Salma_Nazwa_Aurelia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Simple LLM Chat Application (Vanilla Chat)\n",
        "\n",
        "Notebook ini mengimplementasikan aplikasi obrolan baris perintah dasar yang dapat digunakan berulang kali. Buku catatan ini menunjukkan interaksi terprogram dengan API LLM (GPT OpenAI secara default, dengan dukungan opsional untuk Gemini Google) untuk menanggapi masukan pengguna."
      ],
      "metadata": {
        "id": "naERrKSN2xV-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc17ws_ct1Z4",
        "outputId": "ac55cd08-ace7-4fe2-f1a4-c45fc93d4e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# week5_6_task1_chat.ipynb\n",
        "\n",
        "# Import necessary libraries\n",
        "import openai\n",
        "from google.colab import userdata # For API key management in Colab\n",
        "import os\n",
        "\n",
        "# --- Configuration and API Key Setup ---\n",
        "# Securely load your OpenAI API key from Colab Secrets\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    if OPENAI_API_KEY is None:\n",
        "        raise ValueError(\"OpenAI API key not found in Colab Secrets. Please add it.\")\n",
        "    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY # Set it as an environment variable\n",
        "    openai.api_key = OPENAI_API_KEY\n",
        "    print(\"OpenAI API key loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "    print(\"Please ensure your OPENAI_API_KEY is correctly set in Colab Secrets (left sidebar -> ðŸ”‘).\")\n",
        "    OPENAI_API_KEY = None # Ensure it's None if loading failed\n",
        "\n",
        "# (Optional) Setup for Google Gemini API (if you have a key and want to use it)\n",
        "# try:\n",
        "#     GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "#     if GEMINI_API_KEY is None:\n",
        "#         raise ValueError(\"Gemini API key not found in Colab Secrets.\")\n",
        "#     import google.generativeai as genai\n",
        "#     genai.configure(api_key=GEMINI_API_KEY)\n",
        "#     print(\"Google Gemini API key loaded and configured successfully.\")\n",
        "#     # Example: list models to verify\n",
        "#     # for m in genai.list_models():\n",
        "#     #   if 'generateContent' in m.supported_generation_methods:\n",
        "#     #     print(m.name)\n",
        "# except Exception as e:\n",
        "#     print(f\"Error loading or configuring Gemini API key: {e}\")\n",
        "#     GEMINI_API_KEY = None\n",
        "\n",
        "# Choose your LLM model\n",
        "# For OpenAI: \"gpt-3.5-turbo\", \"gpt-4o\"\n",
        "# For Gemini: \"gemini-1.5-flash-latest\", \"gemini-pro\"\n",
        "OPENAI_MODEL_NAME = \"gpt-3.5-turbo\"\n",
        "# GEMINI_MODEL_NAME = \"gemini-1.5-flash-latest\"\n",
        "\n",
        "# Install OpenAI library (if not already installed by Colab)\n",
        "# !pip install openai -q\n",
        "# Install Gemini library (if you plan to use it)\n",
        "# !pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Core Chat Application Logic (Task 1)\n",
        "\n",
        "Add the following code cell for the chat application. This example implements a multi-turn chat using OpenAI."
      ],
      "metadata": {
        "id": "4fJz7dKPwTWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Continue in week5_6_task1_chat.ipynb)\n",
        "\n",
        "# --- Chat Application Logic (OpenAI) ---\n",
        "def run_openai_chat_application():\n",
        "    \"\"\"\n",
        "    Runs a multi-turn command-line chat application using the OpenAI API.\n",
        "    \"\"\"\n",
        "    if not OPENAI_API_KEY:\n",
        "        print(\"OpenAI API key is not available. Cannot start the chat application.\")\n",
        "        return\n",
        "\n",
        "    # Initialize conversation history.\n",
        "    # The first message is a system message to set the LLM's behavior.\n",
        "    conversation_history = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful and friendly assistant.\"}\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n--- Starting OpenAI Chat Application ---\")\n",
        "    print(f\"Model: {OPENAI_MODEL_NAME}\")\n",
        "    print(\"Type 'quit', 'exit', or 'bye' to end the chat session.\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"You: \")\n",
        "            if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "                print(\"\\nAssistant: Goodbye! Thanks for chatting.\")\n",
        "                break\n",
        "\n",
        "            if not user_input.strip(): # Handle empty input from user\n",
        "                print(\"Assistant: Please type a message.\")\n",
        "                continue\n",
        "\n",
        "            # Add user's message to conversation history\n",
        "            conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "            # Make the API call to OpenAI\n",
        "            try:\n",
        "                response = openai.chat.completions.create(\n",
        "                    model=OPENAI_MODEL_NAME,\n",
        "                    messages=conversation_history,\n",
        "                    temperature=0.7, # Controls randomness. Lower is more deterministic.\n",
        "                    max_tokens=150   # Max length of the response.\n",
        "                )\n",
        "\n",
        "                # Extract the assistant's reply\n",
        "                assistant_reply = response.choices[0].message.content.strip()\n",
        "\n",
        "                # Add assistant's reply to conversation history\n",
        "                conversation_history.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "\n",
        "                print(f\"Assistant: {assistant_reply}\")\n",
        "\n",
        "            except openai.APIError as e:\n",
        "                error_message = f\"OpenAI API Error: {e}. Please check your API key, model access, or network.\"\n",
        "                print(f\"Assistant: Sorry, I encountered an API error. ({error_message}) Please try again.\")\n",
        "                # Remove the last user message if the API call failed, so it's not re-processed with the error.\n",
        "                if conversation_history and conversation_history[-1][\"role\"] == \"user\":\n",
        "                    conversation_history.pop()\n",
        "            except Exception as e:\n",
        "                error_message = f\"An unexpected error occurred: {e}\"\n",
        "                print(f\"Assistant: Sorry, an unexpected error occurred. ({error_message}) Please try again.\")\n",
        "                if conversation_history and conversation_history[-1][\"role\"] == \"user\":\n",
        "                    conversation_history.pop()\n",
        "\n",
        "        except EOFError: # Handles Ctrl+D in some environments\n",
        "            print(\"\\nAssistant: Chat ended unexpectedly. Goodbye!\")\n",
        "            break\n",
        "        except KeyboardInterrupt: # Handles Ctrl+C\n",
        "            print(\"\\nAssistant: Chat interrupted. Goodbye!\")\n",
        "            break\n",
        "\n",
        "# --- (Optional) Chat Application Logic (Gemini) ---\n",
        "# def run_gemini_chat_application():\n",
        "#     if not GEMINI_API_KEY:\n",
        "#         print(\"Gemini API key is not available. Cannot start the chat application.\")\n",
        "#         return\n",
        "#\n",
        "#     try:\n",
        "#         model = genai.GenerativeModel(GEMINI_MODEL_NAME,\n",
        "#                                       system_instruction=\"You are a helpful and creative assistant.\") # System prompt\n",
        "#         chat = model.start_chat(history=[]) # Initialize an empty chat history\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error initializing Gemini model: {e}\")\n",
        "#         return\n",
        "#\n",
        "#     print(f\"\\n--- Starting Gemini Chat Application ---\")\n",
        "#     print(f\"Model: {GEMINI_MODEL_NAME}\")\n",
        "#     print(\"Type 'quit', 'exit', or 'bye' to end the chat session.\")\n",
        "#     print(\"-\" * 40)\n",
        "#\n",
        "#     while True:\n",
        "#         try:\n",
        "#             user_input = input(\"You: \")\n",
        "#             if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "#                 print(\"\\nAssistant: Goodbye! Thanks for chatting with Gemini.\")\n",
        "#                 break\n",
        "#             if not user_input.strip():\n",
        "#                 print(\"Assistant: Please type a message.\")\n",
        "#                 continue\n",
        "#\n",
        "#             # Send message to Gemini. History is managed by the 'chat' object.\n",
        "#             try:\n",
        "#                 response = chat.send_message(user_input)\n",
        "#                 assistant_reply = response.text.strip()\n",
        "#                 print(f\"Assistant: {assistant_reply}\")\n",
        "#             except Exception as e: # Broad exception for API errors or content filtering\n",
        "#                 print(f\"Assistant: Sorry, I encountered an error with Gemini. ({e}) Please try again.\")\n",
        "#                 # Note: With Gemini's chat object, managing history after an error might require\n",
        "#                 # inspecting chat.history and potentially removing the last user part if needed.\n",
        "#\n",
        "#         except EOFError:\n",
        "#             print(\"\\nAssistant: Chat ended unexpectedly. Goodbye!\")\n",
        "#             break\n",
        "#         except KeyboardInterrupt:\n",
        "#             print(\"\\nAssistant: Chat interrupted. Goodbye!\")\n",
        "#             break\n",
        "\n",
        "# --- Main Execution for Task 1 ---\n",
        "if __name__ == \"__main__\":\n",
        "    # To run the chat, call the function.\n",
        "    # Make sure the API key was loaded successfully.\n",
        "    if OPENAI_API_KEY:\n",
        "        print(\"Starting OpenAI chat. If you prefer Gemini and have set it up, modify the call below.\")\n",
        "        run_openai_chat_application()\n",
        "    # elif GEMINI_API_KEY: # Uncomment if you want to default to Gemini if OpenAI fails or is not set\n",
        "    #     print(\"OpenAI key not found or failed to load. Starting Gemini chat.\")\n",
        "    #     run_gemini_chat_application()\n",
        "    else:\n",
        "        print(\"No API key is available (OpenAI or Gemini). Chat application cannot start.\")\n",
        "        print(\"Please ensure 'OPENAI_API_KEY' (and/or 'GEMINI_API_KEY') is set in Colab Secrets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhjo6HvivRJR",
        "outputId": "2735444f-89cd-422e-9091-cd6c7b235213"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting OpenAI chat. If you prefer Gemini and have set it up, modify the call below.\n",
            "\n",
            "--- Starting OpenAI Chat Application ---\n",
            "Model: gpt-3.5-turbo\n",
            "Type 'quit', 'exit', or 'bye' to end the chat session.\n",
            "----------------------------------------\n",
            "You: Hello, whatchu doin'?\n",
            "Assistant: Hello! I'm here to help you with any questions or tasks you have. How can I assist you today?\n",
            "You: Can u help me to answer this question : 100 x 100?\n",
            "Assistant: Of course! The answer to 100 x 100 is 10,000. Let me know if you need help with anything else!\n",
            "You: Thankyou!\n",
            "Assistant: You're welcome! If you have any more questions or need assistance in the future, feel free to ask. Have a great day!\n",
            "You: Bye!\n",
            "Assistant: Goodbye! Take care!\n",
            "You: quit\n",
            "\n",
            "Assistant: Goodbye! Thanks for chatting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Markdown Documentation and Example Interactions (Task 1)\n",
        "\n",
        "Add a markdown cell below your code cells in week5_6_task1_chat.ipynb."
      ],
      "metadata": {
        "id": "zyVU6wLnwiKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# --- API Key Configuration ---\n",
        "# Access OpenAI API key from Colab Secrets\n",
        "try:\n",
        "    OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "    if OPENAI_API_KEY:\n",
        "        openai.api_key = OPENAI_API_KEY\n",
        "        print(\"OpenAI API key loaded successfully.\")\n",
        "    else:\n",
        "        print(\"OPENAI_API_KEY not found in Colab Secrets. Please add it.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading OpenAI API key: {e}\")\n",
        "\n",
        "# Access Gemini API key from Colab Secrets (optional)\n",
        "try:\n",
        "    GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "    if GEMINI_API_KEY:\n",
        "        genai.configure(api_key=GEMINI_API_KEY)\n",
        "        print(\"Gemini API key loaded successfully.\")\n",
        "    else:\n",
        "        print(\"GEMINI_API_KEY not found in Colab Secrets. Gemini functionality might be limited.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Gemini API key: {e}\")\n",
        "\n",
        "# --- LLM Model Configuration ---\n",
        "OPENAI_MODEL_NAME = \"gpt-3.5-turbo\" # You can change this to \"gpt-4o\" or other models\n",
        "GEMINI_MODEL_NAME = \"gemini-1.5-flash-latest\" # Or \"gemini-1.5-pro-latest\"\n",
        "\n",
        "# Initial system message for OpenAI\n",
        "OPENAI_SYSTEM_PROMPT = {\"role\": \"system\", \"content\": \"You are a helpful and friendly assistant.\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFQa33zQx6Lz",
        "outputId": "6e273ae4-7d9f-41ca-c8de-e8baf61df41b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API key loaded successfully.\n",
            "GEMINI_API_KEY not found in Colab Secrets. Gemini functionality might be limited.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import google.generativeai as genai\n",
        "import sys\n",
        "\n",
        "# --- OpenAI Chat Application ---\n",
        "def run_openai_chat_application(model_name, system_prompt):\n",
        "    print(f\"\\n--- Starting OpenAI Chat Application ---\")\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Type 'quit', 'exit', or 'bye' to end the chat session.\")\n",
        "    print(\"----------------------------------------\")\n",
        "\n",
        "    conversation_history = [system_prompt]\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"You: \")\n",
        "            if user_input.lower() in ['quit', 'exit', 'bye']:\n",
        "                print(\"Assistant: Goodbye! Thanks for chatting.\")\n",
        "                break\n",
        "\n",
        "            conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "            response = openai.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=conversation_history,\n",
        "                temperature=0.7, # Adjust for creativity vs. consistency\n",
        "            )\n",
        "\n",
        "            assistant_response = response.choices[0].message.content\n",
        "            print(f\"Assistant: {assistant_response}\")\n",
        "            conversation_history.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "        except openai.APIError as e:\n",
        "            print(f\"OpenAI API Error: {e}\")\n",
        "            print(\"Please check your API key and network connection.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "            # Optionally, you might want to log the full traceback for debugging\n",
        "            # import traceback\n",
        "            # traceback.print_exc()\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nChat session interrupted. Goodbye!\")\n",
        "            break\n",
        "\n",
        "# --- Gemini Chat Application (Optional - Uncomment and configure to use) ---\n",
        "def run_gemini_chat_application(model_name):\n",
        "    # Ensure GEMINI_API_KEY is loaded in the first cell\n",
        "    if not os.environ.get(\"GEMINI_API_KEY\"):\n",
        "        print(\"Gemini API key not found. Cannot run Gemini chat.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n--- Starting Gemini Chat Application ---\")\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Type 'quit', 'exit', or 'bye' to end the chat session.\")\n",
        "    print(\"----------------------------------------\")\n",
        "\n",
        "    try:\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        chat = model.start_chat(history=[]) # Initialize with empty history\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Gemini model or chat: {e}\")\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"You: \")\n",
        "            if user_input.lower() in ['quit', 'exit', 'bye']:\n",
        "                print(\"Assistant: Goodbye! Thanks for chatting.\")\n",
        "                break\n",
        "\n",
        "            response = chat.send_message(user_input)\n",
        "            assistant_response = response.text\n",
        "            print(f\"Assistant: {assistant_response}\")\n",
        "\n",
        "        except genai.types.core.ClientError as e:\n",
        "            print(f\"Gemini API Error: {e}\")\n",
        "            print(\"Please check your API key and network connection.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nChat session interrupted. Goodbye!\")\n",
        "            break\n",
        "\n",
        "# --- Main execution block ---\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Choose which chat application to run ---\n",
        "    # By default, runs OpenAI. Uncomment the Gemini line to use Gemini instead.\n",
        "\n",
        "    # Option 1: Run OpenAI Chat\n",
        "    if OPENAI_API_KEY: # Only try to run if OpenAI key is available\n",
        "        print(\"Starting OpenAI chat. If you prefer Gemini and have set it up, modify the call below.\")\n",
        "        run_openai_chat_application(OPENAI_MODEL_NAME, OPENAI_SYSTEM_PROMPT)\n",
        "    else:\n",
        "        print(\"OpenAI API key not set. Cannot start OpenAI chat.\")\n",
        "\n",
        "    # Option 2: Run Gemini Chat (Uncomment the following lines to use Gemini)\n",
        "    # if GEMINI_API_KEY: # Only try to run if Gemini key is available\n",
        "    #     print(\"Starting Gemini chat. Make sure you've configured GEMINI_API_KEY.\")\n",
        "    #     run_gemini_chat_application(GEMINI_MODEL_NAME)\n",
        "    # else:\n",
        "    #     print(\"Gemini API key not set. Cannot start Gemini chat.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0CZ5YiZx-tV",
        "outputId": "26783f19-7ffc-4980-81ce-18e90a167b77"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting OpenAI chat. If you prefer Gemini and have set it up, modify the call below.\n",
            "\n",
            "--- Starting OpenAI Chat Application ---\n",
            "Model: gpt-3.5-turbo\n",
            "Type 'quit', 'exit', or 'bye' to end the chat session.\n",
            "----------------------------------------\n",
            "You: Hello\n",
            "Assistant: Hello! How can I assist you today?\n",
            "You: Can u help me answer this question : what the meaning of FOMO?\n",
            "Assistant: Of course! FOMO stands for \"fear of missing out.\" It is a feeling of anxiety or insecurity that you might be missing out on rewarding experiences that others are having.\n",
            "You: Okay ,Thank You!\n",
            "Assistant: You're welcome! If you have any more questions or need assistance with anything else, feel free to ask. Have a great day!\n",
            "You: quit\n",
            "Assistant: Goodbye! Thanks for chatting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas openai google-generativeai # Jalankan ini jika belum terinstal\n",
        "import pandas as pd\n",
        "import os\n",
        "import openai\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Pastikan API Keys sudah dimuat dari cell sebelumnya atau muat lagi jika ini notebook terpisah\n",
        "# Contoh:\n",
        "# try:\n",
        "#     OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "#     if OPENAI_API_KEY:\n",
        "#         openai.api_key = OPENAI_API_KEY\n",
        "#         print(\"OpenAI API key loaded successfully for Task 2.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error loading OpenAI API key for Task 2: {e}\")\n",
        "#\n",
        "# try:\n",
        "#     GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
        "#     if GEMINI_API_KEY:\n",
        "#         genai.configure(api_key=GEMINI_API_KEY)\n",
        "#         print(\"Gemini API key loaded successfully for Task 2.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error loading Gemini API key for Task 2: {e}\")\n",
        "\n",
        "# Konfigurasi model (bisa sama dengan Task 1 atau berbeda)\n",
        "OPENAI_MODEL_NAME_T2 = \"gpt-3.5-turbo\"\n",
        "GEMINI_MODEL_NAME_T2 = \"gemini-1.5-flash-latest\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfJOx9S1zQtC",
        "outputId": "891a3687-b945-4a6f-d1d8-871ef692ee8f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh: Mengunduh atau membuat dataset\n",
        "# Jika dari Kaggle, Anda mungkin perlu mengunduh file CSV dan mengunggahnya ke Colab\n",
        "# atau menggunakan Kaggle API. Untuk contoh ini, saya akan membuat dataset sintetis sederhana.\n",
        "\n",
        "data = {\n",
        "    'product_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
        "    'product_name': ['Smartphone X', 'Laptop Pro', 'Smartwatch 5', 'Wireless Earbuds', 'Portable Speaker'],\n",
        "    'review_text': [\n",
        "        'Love this phone! The camera is amazing and the battery lasts forever.',\n",
        "        'Good laptop for the price, but it gets a bit hot when gaming.',\n",
        "        'Sleek design and accurate health tracking. Battery life is decent.',\n",
        "        'Excellent sound quality and comfortable fit. Connection is stable.',\n",
        "        'Sound is okay, but the bass is weak. Portable design is a plus.'\n",
        "    ],\n",
        "    'rating': [5, 4, 4, 5, 3]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Jika Anda memiliki file CSV, ganti dengan ini:\n",
        "# df = pd.read_csv('nama_file_anda.csv')\n",
        "\n",
        "print(\"Dataset Loaded:\")\n",
        "print(df.head())\n",
        "print(f\"\\nJumlah baris dalam dataset: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBNZxwPzzlDM",
        "outputId": "85740466-04f7-48c6-e480-818021549dbf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded:\n",
            "  product_id      product_name  \\\n",
            "0       P001      Smartphone X   \n",
            "1       P002        Laptop Pro   \n",
            "2       P003      Smartwatch 5   \n",
            "3       P004  Wireless Earbuds   \n",
            "4       P005  Portable Speaker   \n",
            "\n",
            "                                         review_text  rating  \n",
            "0  Love this phone! The camera is amazing and the...       5  \n",
            "1  Good laptop for the price, but it gets a bit h...       4  \n",
            "2  Sleek design and accurate health tracking. Bat...       4  \n",
            "3  Excellent sound quality and comfortable fit. C...       5  \n",
            "4  Sound is okay, but the bass is weak. Portable ...       3  \n",
            "\n",
            "Jumlah baris dalam dataset: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk memanggil OpenAI API\n",
        "def get_openai_sentiment(review_text, model_name=OPENAI_MODEL_NAME_T2):\n",
        "    try:\n",
        "        # Prompt yang akan dikirim ke LLM\n",
        "        # Anda bisa menyesuaikan prompt ini sesuai dengan tugas Anda\n",
        "        prompt = f\"Analyze the sentiment of the following product review: '{review_text}'. Respond with 'Positive', 'Negative', or 'Neutral'.\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that analyzes sentiment.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "        response = openai.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=messages,\n",
        "            temperature=0.0 # Lebih rendah untuk tugas yang faktual/konsisten\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except openai.APIError as e:\n",
        "        print(f\"OpenAI API Error for review '{review_text[:50]}...': {e}\")\n",
        "        return \"Error\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred for review '{review_text[:50]}...': {e}\")\n",
        "        return \"Error\"\n",
        "\n",
        "# Fungsi untuk memanggil Gemini API (jika Anda ingin menggunakan Gemini)\n",
        "def get_gemini_sentiment(review_text, model_name=GEMINI_MODEL_NAME_T2):\n",
        "    try:\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        # Prompt yang akan dikirim ke LLM\n",
        "        prompt = f\"Analyze the sentiment of the following product review: '{review_text}'. Respond with 'Positive', 'Negative', or 'Neutral'.\"\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except genai.types.core.ClientError as e:\n",
        "        print(f\"Gemini API Error for review '{review_text[:50]}...': {e}\")\n",
        "        return \"Error\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred for review '{review_text[:50]}...': {e}\")\n",
        "        return \"Error\"\n",
        "\n",
        "# Iterasi melalui baris DataFrame dan terapkan fungsi LLM\n",
        "# Batasi jumlah baris untuk pengujian agar tidak menghabiskan terlalu banyak token/kuota API\n",
        "# Ganti 'review_text' dengan nama kolom teks Anda yang sebenarnya\n",
        "df['llm_sentiment'] = df['review_text'].apply(lambda x: get_openai_sentiment(x))\n",
        "# Atau jika Anda ingin menggunakan Gemini:\n",
        "# df['llm_sentiment'] = df['review_text'].apply(lambda x: get_gemini_sentiment(x))\n",
        "\n",
        "print(\"\\nProcessing complete. Here are the results:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGA7nfzKznzl",
        "outputId": "ad90c447-4011-41fb-a7c1-722063e1a277"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing complete. Here are the results:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan DataFrame dengan kolom baru yang berisi hasil LLM\n",
        "# Anda bisa memilih kolom mana saja yang ingin ditampilkan\n",
        "display_df = df[['product_name', 'review_text', 'rating', 'llm_sentiment']]\n",
        "print(display_df.to_markdown(index=False)) # Untuk tampilan yang rapi di markdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnFiGc1Vzxf9",
        "outputId": "5457db1f-af20-49ea-ce3d-509d4f49fa52"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| product_name     | review_text                                                           |   rating | llm_sentiment   |\n",
            "|:-----------------|:----------------------------------------------------------------------|---------:|:----------------|\n",
            "| Smartphone X     | Love this phone! The camera is amazing and the battery lasts forever. |        5 | Positive        |\n",
            "| Laptop Pro       | Good laptop for the price, but it gets a bit hot when gaming.         |        4 | Neutral         |\n",
            "| Smartwatch 5     | Sleek design and accurate health tracking. Battery life is decent.    |        4 | Positive        |\n",
            "| Wireless Earbuds | Excellent sound quality and comfortable fit. Connection is stable.    |        5 | Positive        |\n",
            "| Portable Speaker | Sound is okay, but the bass is weak. Portable design is a plus.       |        3 | Neutral         |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: LLM-Powered Tabular Data Processing\n",
        "\n",
        "## Tujuan\n",
        "\n",
        "Tugas ini bertujuan untuk menerapkan Large Language Models (LLMs) secara programatik untuk memproses multiple rows of data dari sumber tabular. Konsepnya mirip dengan \"asking the same question to N rows\" yang telah didemonstrasikan dalam sesi live coding.\n",
        "\n",
        "---\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "PL13jLg21l4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installasi library yang mungkin dibutuhkan (jalankan hanya jika belum terinstal)\n",
        "!pip install pandas openai google-generativeai\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import openai\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Pastikan API Keys sudah dimuat dari cell sebelumnya\n",
        "# Jika ini adalah notebook terpisah, Anda perlu memuat ulang API key di sini:\n",
        "# try:\n",
        "#     OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "#     if OPENAI_API_KEY:\n",
        "#         openai.api_key = OPENAI_API_KEY\n",
        "#         print(\"OpenAI API key loaded successfully for Task 2.\")\n",
        "#     else:\n",
        "#         print(\"OPENAI_API_KEY not found in Colab Secrets. Please add it.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error loading OpenAI API key for Task 2: {e}\")\n",
        "\n",
        "# Konfigurasi model untuk Task 2\n",
        "OPENAI_MODEL_NAME_T2 = \"gpt-3.5-turbo\" # Bisa diubah ke gpt-4o, dll.\n",
        "GEMINI_MODEL_NAME_T2 = \"gemini-1.5-flash-latest\" # Bisa diubah ke gemini-1.5-pro-latest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0C13uOc1mka",
        "outputId": "3a2fd380-20c0-447c-f10e-5bf64054b98b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Selection\n",
        "\n",
        "Untuk tugas ini, saya memilih/membuat dataset [**Ganti dengan nama dataset Anda, contoh: \"Product Review Sentiment Data\"**].\n",
        "\n",
        "* **Sumber Dataset:**\n",
        "    * Jika dari Kaggle: [Sertakan **link URL langsung** ke dataset di Kaggle, contoh: `https://www.kaggle.com/datasets/your_dataset_name`]\n",
        "    * Jika sintetis/buatan sendiri: [Deskripsikan bagaimana Anda membuat dataset ini, contoh: \"Dataset ini dibuat secara sintetis untuk demonstrasi analisis sentimen, berisi ulasan produk fiktif dan rating.\"]\n",
        "\n",
        "* **Alasan Pemilihan:**\n",
        "    Dataset ini dipilih karena [Jelaskan **mengapa dataset ini cocok** untuk tugas Anda. Contoh: \"memiliki kolom teks (`review_text`) yang ideal untuk dianalisis sentimennya menggunakan LLM, serta kolom rating sebagai pembanding.\"]."
      ],
      "metadata": {
        "id": "YRAt_g3j1uEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Loading & Iteration ---\n",
        "\n",
        "# Contoh: Membuat dataset sintetis (Ganti dengan kode loading dataset Anda yang sebenarnya)\n",
        "# Jika Anda punya file CSV, unggah ke Colab dan gunakan:\n",
        "# df = pd.read_csv('nama_file_anda.csv')\n",
        "\n",
        "data = {\n",
        "    'product_id': ['P001', 'P002', 'P003', 'P004', 'P005', 'P006', 'P007', 'P008', 'P009', 'P010'],\n",
        "    'product_name': ['Smartphone X', 'Laptop Pro', 'Smartwatch 5', 'Wireless Earbuds', 'Portable Speaker',\n",
        "                     'Gaming Mouse', 'Mechanical Keyboard', 'Webcam HD', 'Monitor UltraWide', 'Noise Cancelling Headphones'],\n",
        "    'review_text': [\n",
        "        'Love this phone! The camera is amazing and the battery lasts forever. Definitely worth the price.',\n",
        "        'Good laptop for the price, but it gets a bit hot when gaming. Screen quality is superb though.',\n",
        "        'Sleek design and accurate health tracking. Battery life is decent for daily use.',\n",
        "        'Excellent sound quality and comfortable fit. Connection is stable even far from device.',\n",
        "        'Sound is okay, but the bass is weak. Portable design is a plus, but not for audiophiles.',\n",
        "        'Smooth tracking and good click response. RGB lights are a nice touch, but software is clunky.',\n",
        "        'Typing experience is fantastic, very tactile. A bit loud for office use, but great for gaming.',\n",
        "        'Clear video and microphone for calls. Easy to set up, but auto-focus can be slow sometimes.',\n",
        "        'Immersive viewing experience with vibrant colors. Great for multitasking, but stand is a bit wobbly.',\n",
        "        'Very effective at blocking out noise, comfortable for long flights. Audio quality is clear but not exceptional bass.'\n",
        "    ],\n",
        "    'rating': [5, 4, 4, 5, 3, 4, 5, 4, 4, 5]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Dataset Loaded:\")\n",
        "# Menampilkan 5 baris pertama dan info dasar\n",
        "print(df.head())\n",
        "print(f\"\\nJumlah baris dalam dataset: {len(df)}\")\n",
        "print(\"\\nKolom yang tersedia:\")\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxJr-aXA1vI4",
        "outputId": "d6f619c5-c4a5-439c-95e6-f8075024ff7e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded:\n",
            "  product_id      product_name  \\\n",
            "0       P001      Smartphone X   \n",
            "1       P002        Laptop Pro   \n",
            "2       P003      Smartwatch 5   \n",
            "3       P004  Wireless Earbuds   \n",
            "4       P005  Portable Speaker   \n",
            "\n",
            "                                         review_text  rating  \n",
            "0  Love this phone! The camera is amazing and the...       5  \n",
            "1  Good laptop for the price, but it gets a bit h...       4  \n",
            "2  Sleek design and accurate health tracking. Bat...       4  \n",
            "3  Excellent sound quality and comfortable fit. C...       5  \n",
            "4  Sound is okay, but the bass is weak. Portable ...       3  \n",
            "\n",
            "Jumlah baris dalam dataset: 10\n",
            "\n",
            "Kolom yang tersedia:\n",
            "['product_id', 'product_name', 'review_text', 'rating']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Prompting per Row\n",
        "\n",
        "Tugas yang saya minta dari LLM untuk setiap baris data adalah **[Ganti dengan tugas LLM Anda, contoh: \"Analisis Sentimen\"]**. LLM akan mengekstrak sentimen dari kolom `review_text` dan mengklasifikasikannya sebagai 'Positive', 'Negative', atau 'Neutral'.\n",
        "\n",
        "**Struktur Prompt yang Digunakan:**\n",
        "\n",
        "Untuk setiap baris, prompt akan diformulasikan sebagai berikut:"
      ],
      "metadata": {
        "id": "SznaoolC10vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LLM Prompting per Row & Response Handling ---\n",
        "\n",
        "# Fungsi untuk memanggil OpenAI API untuk analisis sentimen\n",
        "def get_openai_sentiment(review_text, model_name=OPENAI_MODEL_NAME_T2):\n",
        "    try:\n",
        "        prompt = f\"Analyze the sentiment of the following product review: '{review_text}'. Respond with 'Positive', 'Negative', or 'Neutral'.\"\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that analyzes sentiment and responds only with 'Positive', 'Negative', or 'Neutral'.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "        response = openai.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=messages,\n",
        "            temperature=0.0, # Rendah untuk konsistensi\n",
        "            max_tokens=10 # Batasi token untuk respons singkat\n",
        "        )\n",
        "        return response.choices[0].message.content.strip() # Menghapus spasi ekstra\n",
        "    except openai.APIError as e:\n",
        "        print(f\"OpenAI API Error for review '{review_text[:50]}...': {e}\")\n",
        "        return \"Error: API issue\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred for review '{review_text[:50]}...': {e}\")\n",
        "        return \"Error: Processing issue\"\n",
        "\n",
        "# Fungsi untuk memanggil Gemini API untuk analisis sentimen (opsional, jika ingin pakai Gemini)\n",
        "def get_gemini_sentiment(review_text, model_name=GEMINI_MODEL_NAME_T2):\n",
        "    try:\n",
        "        # Pastikan GEMINI_API_KEY sudah dikonfigurasi di awal notebook\n",
        "        if not genai.configure().api_key:\n",
        "            return \"Error: Gemini API key not configured.\"\n",
        "\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        prompt = f\"Analyze the sentiment of the following product review: '{review_text}'. Respond only with 'Positive', 'Negative', or 'Neutral'.\"\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "    except genai.types.core.ClientError as e:\n",
        "        print(f\"Gemini API Error for review '{review_text[:50]}...': {e}\")\n",
        "        return \"Error: API issue\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred for review '{review_text[:50]}...': {e}\")\n",
        "        return \"Error: Processing issue\"\n",
        "\n",
        "print(f\"Starting LLM processing for {len(df)} rows. This might take a moment...\")\n",
        "\n",
        "# Terapkan fungsi LLM ke setiap baris pada kolom 'review_text'\n",
        "# Gunakan .copy() jika Anda mengambil sampel dari DataFrame yang lebih besar untuk menghindari SettingWithCopyWarning\n",
        "# df_sample = df.head(10).copy() # Untuk menguji hanya beberapa baris\n",
        "\n",
        "# Pilih fungsi LLM yang akan Anda gunakan (OpenAI atau Gemini)\n",
        "df['llm_sentiment'] = df['review_text'].apply(lambda x: get_openai_sentiment(x))\n",
        "# Atau jika Anda ingin menggunakan Gemini:\n",
        "# df['llm_sentiment'] = df['review_text'].apply(lambda x: get_gemini_sentiment(x))\n",
        "\n",
        "print(\"\\nLLM processing complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVxtFz_P11Zv",
        "outputId": "449a389e-0a85-49b5-8db8-89da08c237c5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting LLM processing for 10 rows. This might take a moment...\n",
            "\n",
            "LLM processing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Kode: Presentation of Results"
      ],
      "metadata": {
        "id": "e1avon832Kg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Presentation of Results ---\n",
        "\n",
        "print(\"\\n--- Original Data and LLM-Generated Sentiments ---\")\n",
        "\n",
        "# Menampilkan DataFrame dengan kolom yang relevan\n",
        "# Anda bisa menyesuaikan kolom mana saja yang ingin ditampilkan\n",
        "display_df = df[['product_name', 'review_text', 'rating', 'llm_sentiment']]\n",
        "\n",
        "# Gunakan to_markdown() untuk tampilan yang rapi di notebook\n",
        "# atau to_string() jika Anda ingin melihat semua baris tanpa truncasi\n",
        "print(display_df.to_markdown(index=False))\n",
        "\n",
        "# Analisis sederhana (opsional)\n",
        "print(\"\\n--- Sentiment Analysis Summary ---\")\n",
        "print(df['llm_sentiment'].value_counts().to_markdown())\n",
        "\n",
        "# Anda juga bisa membandingkan dengan rating asli jika relevan\n",
        "# print(\"\\nComparison of LLM Sentiment vs. Original Rating:\")\n",
        "# # Contoh sederhana: Konversi rating ke sentimen dasar untuk perbandingan\n",
        "# df['original_sentiment'] = df['rating'].apply(lambda x: 'Positive' if x >=4 else ('Negative' if x <=2 else 'Neutral'))\n",
        "# print(df[['review_text', 'llm_sentiment', 'original_sentiment']].to_markdown(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q63m1B7C1774",
        "outputId": "e8d03715-21ce-4e55-d39e-75e8179dd0b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Original Data and LLM-Generated Sentiments ---\n",
            "| product_name                | review_text                                                                                                          |   rating | llm_sentiment   |\n",
            "|:----------------------------|:---------------------------------------------------------------------------------------------------------------------|---------:|:----------------|\n",
            "| Smartphone X                | Love this phone! The camera is amazing and the battery lasts forever. Definitely worth the price.                    |        5 | Positive        |\n",
            "| Laptop Pro                  | Good laptop for the price, but it gets a bit hot when gaming. Screen quality is superb though.                       |        4 | Positive        |\n",
            "| Smartwatch 5                | Sleek design and accurate health tracking. Battery life is decent for daily use.                                     |        4 | Positive        |\n",
            "| Wireless Earbuds            | Excellent sound quality and comfortable fit. Connection is stable even far from device.                              |        5 | Positive        |\n",
            "| Portable Speaker            | Sound is okay, but the bass is weak. Portable design is a plus, but not for audiophiles.                             |        3 | Negative        |\n",
            "| Gaming Mouse                | Smooth tracking and good click response. RGB lights are a nice touch, but software is clunky.                        |        4 | Negative        |\n",
            "| Mechanical Keyboard         | Typing experience is fantastic, very tactile. A bit loud for office use, but great for gaming.                       |        5 | Positive        |\n",
            "| Webcam HD                   | Clear video and microphone for calls. Easy to set up, but auto-focus can be slow sometimes.                          |        4 | Positive        |\n",
            "| Monitor UltraWide           | Immersive viewing experience with vibrant colors. Great for multitasking, but stand is a bit wobbly.                 |        4 | Positive        |\n",
            "| Noise Cancelling Headphones | Very effective at blocking out noise, comfortable for long flights. Audio quality is clear but not exceptional bass. |        5 | Positive        |\n",
            "\n",
            "--- Sentiment Analysis Summary ---\n",
            "| llm_sentiment   |   count |\n",
            "|:----------------|--------:|\n",
            "| Positive        |       8 |\n",
            "| Negative        |       2 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baik, ini adalah kesimpulan dari seluruh tugas dan panduan yang telah kita bahas, mencakup kedua Task (1 dan 2) serta potensi Bonus Task.\n",
        "Kesimpulan: Aplikasi LLM Programatik Anda\n",
        "\n",
        "Anda telah berhasil membangun dan mendokumentasikan dua aplikasi utama menggunakan Large Language Models (LLMs) secara programatik:\n",
        "Task 1: Aplikasi Chat LLM Sederhana (Vanilla Chat)\n",
        "\n",
        "Anda telah membuat aplikasi chat berbasis command-line yang memungkinkan interaksi multi-turn dengan LLM (baik OpenAI GPT atau Google Gemini). Aplikasi ini berfungsi dengan cara mengirimkan input pengguna ke API LLM dan menampilkan respons yang dihasilkan. Fitur penting dari aplikasi ini adalah kemampuannya untuk mempertahankan konteks percakapan melalui riwayat obrolan, yang memungkinkan LLM memberikan respons yang lebih koheren dan relevan dalam percakapan yang berkelanjutan. Anda juga telah mengimplementasikan penanganan API Key yang aman menggunakan Colab Secrets, sesuai praktik terbaik.\n",
        "Task 2: Pemrosesan Data Tabular dengan LLM\n",
        "\n",
        "Selain chat, Anda juga telah berhasil menerapkan LLM untuk memproses data tabular. Anda telah memilih atau membuat dataset, memuatnya ke dalam DataFrame, dan mengiterasi setiap baris. Untuk setiap baris, Anda merumuskan prompt khusus yang memanfaatkan data dari kolom-kolom tertentu (misalnya, review_text), lalu mengirimkan prompt tersebut ke LLM. Respons dari LLM kemudian diambil dan disimpan kembali ke dalam DataFrame Anda sebagai kolom baru, yang kemudian ditampilkan. Ini menunjukkan kemampuan LLM untuk memproses data secara massal dan mengekstrak atau menghasilkan informasi spesifik dari setiap entri. Contoh yang dibahas adalah analisis sentimen, tetapi konsep ini dapat diterapkan untuk berbagai tugas seperti peringkasan, kategorisasi, atau ekstraksi entitas.\n",
        "Potensi Bonus Task: Integrasi Fitur LLM Lanjutan\n",
        "\n",
        "Jika Anda memilih untuk melanjutkan ke Bonus Task, Anda memiliki kesempatan untuk meningkatkan salah satu aplikasi Anda dengan fitur-fitur canggih seperti Multimodal Interaction, Agentic Behavior/Tool Use/Function Calling, atau Retrieval Augmented Generation (RAG). Mengimplementasikan fitur-fitur ini tidak hanya akan menunjukkan pemahaman mendalam Anda tentang kemampuan LLM, tetapi juga kemampuan Anda untuk membangun sistem AI yang lebih kompleks dan cerdas. Ini akan menambah nilai signifikan pada proyek Anda, misalnya, dengan memungkinkan chatbot Anda untuk memproses gambar, memanggil fungsi eksternal untuk mendapatkan informasi real-time, atau memberikan jawaban yang lebih akurat berdasarkan basis pengetahuan spesifik.\n",
        "Kesiapan Pengumpulan\n",
        "\n",
        "Dengan selesainya kedua tugas inti dan didokumentasikannya dengan baik di notebook Anda (termasuk kode, komentar, bagian markdown untuk deskripsi, dan contoh interaksi/output), Anda telah memenuhi persyaratan utama dari tugas gabungan Minggu 5 & 6 ini. Pastikan Anda telah mengulas semua bagian dari rubrik penilaian untuk memastikan tidak ada detail yang terlewat, terutama terkait keamanan API Key dan format pengumpulan di GitHub.\n",
        "\n",
        "Selamat atas penyelesaian tugas yang komprehensif ini! Ini adalah langkah besar dalam memahami dan menerapkan kekuatan LLM secara programatik.\n"
      ],
      "metadata": {
        "id": "iKmdJbcQ2SdY"
      }
    }
  ]
}